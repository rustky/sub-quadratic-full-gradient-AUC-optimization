{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e15d34d-b646-466f-b867-a74addaa1a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 13:59:54.508548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-21 13:59:54.508567: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from libauc.losses import AUCMLoss\n",
    "from libauc.optimizers import PESG\n",
    "from libauc.models import ResNet20\n",
    "from libauc.datasets import CIFAR10\n",
    "from libauc.datasets import ImbalanceGenerator \n",
    "\n",
    "import torch \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from functional_square_loss import functional_square_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76cc53c-de33-49c3-a830-f3ee6b6f49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(SEED):\n",
    "    # REPRODUCIBILITY\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "220e2a51-6feb-4e26-b75d-c8f07aa2e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, targets, image_size=32, crop_size=30, mode='train'):\n",
    "       self.images = images.astype(np.uint8)\n",
    "       self.targets = targets\n",
    "       self.mode = mode\n",
    "       self.transform_train = transforms.Compose([                                                \n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.RandomCrop((crop_size, crop_size), padding=None),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.Resize((image_size, image_size)),\n",
    "                              ])\n",
    "       self.transform_test = transforms.Compose([\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Resize((image_size, image_size)),\n",
    "                              ])\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        target = self.targets[idx]\n",
    "        image = Image.fromarray(image.astype('uint8'))\n",
    "        if self.mode == 'train':\n",
    "            image = self.transform_train(image)\n",
    "        else:\n",
    "            image = self.transform_test(image)\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60aa2696-e753-4b79-8fb8-7ec8ad70d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramaters\n",
    "SEED = 123\n",
    "BATCH_SIZE = 128\n",
    "imratio = 0.1\n",
    "lr = 0.1\n",
    "gamma = 500\n",
    "weight_decay = 1e-4\n",
    "margin = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661da73b-28cc-4f84-b89b-605bc1db01f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_SAMPLES: [27777], POS:NEG: [2777 : 25000], POS_RATIO: 0.1000\n",
      "NUM_SAMPLES: [10000], POS:NEG: [5000 : 5000], POS_RATIO: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# dataloader \n",
    "(train_data, train_label), (test_data, test_label) = CIFAR10()\n",
    "(train_images, train_labels) = ImbalanceGenerator(train_data, train_label, imratio=imratio, shuffle=True, random_seed=SEED)\n",
    "(test_images, test_labels) = ImbalanceGenerator(test_data, test_label, is_balanced=True,  random_seed=SEED)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(ImageDataset(train_images, train_labels), batch_size=BATCH_SIZE, shuffle=True, num_workers=1, pin_memory=True, drop_last=True)\n",
    "testloader = torch.utils.data.DataLoader( ImageDataset(test_images, test_labels, mode='test'), batch_size=BATCH_SIZE, shuffle=False, num_workers=1,  pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165692f9-74fa-4325-96ac-f99f380628eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet20(pretrained=False, last_activation='sigmoid', num_classes=1)\n",
    "# Loss = AUCMLoss(imratio=imratio)\n",
    "# Loss = functional_square_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae15c6f3-979c-4b03-84a4-6ccc3fea410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = [AUCMLoss(imratio=imratio), functional_square_loss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67b85714-2407-4849-90ca-bc4a5a756904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCMLoss()\n",
      "Start Training\n",
      "------------------------------\n",
      "epoch: 0, train_loss: 0.099761, train_auc:0.586853, test_auc:0.644864, lr:0.100000\n",
      "epoch: 1, train_loss: 0.059273, train_auc:0.650085, test_auc:0.676143, lr:0.100000\n",
      "epoch: 2, train_loss: 0.017393, train_auc:0.682776, test_auc:0.673050, lr:0.100000\n",
      "epoch: 3, train_loss: 0.033036, train_auc:0.703107, test_auc:0.684653, lr:0.100000\n",
      "epoch: 4, train_loss: 0.048445, train_auc:0.718602, test_auc:0.703560, lr:0.100000\n",
      "functional_square_loss()\n",
      "Start Training\n",
      "------------------------------\n",
      "epoch: 0, train_loss: 1495.000000, train_auc:0.516361, test_auc:0.523993, lr:0.100000\n",
      "epoch: 1, train_loss: 1791.998779, train_auc:0.517060, test_auc:0.517383, lr:0.100000\n",
      "epoch: 2, train_loss: 1596.000000, train_auc:0.515252, test_auc:0.502749, lr:0.100000\n",
      "epoch: 3, train_loss: 1071.000000, train_auc:0.499616, test_auc:0.500000, lr:0.100000\n",
      "epoch: 4, train_loss: 1596.000000, train_auc:0.500000, test_auc:0.500000, lr:0.100000\n"
     ]
    }
   ],
   "source": [
    "for loss_function in loss_list:\n",
    "    optimizer = PESG(model, \n",
    "                 a=loss_function.a, \n",
    "                 b=loss_function.b, \n",
    "                 alpha=loss_function.alpha, \n",
    "                 imratio=imratio, \n",
    "                 lr=lr, \n",
    "                 gamma=gamma, \n",
    "                 margin=margin, \n",
    "                 weight_decay=weight_decay)\n",
    "    print(str(loss_function))\n",
    "    print ('Start Training')\n",
    "    print ('-'*30)\n",
    "    for epoch in range(5):\n",
    "\n",
    "         if epoch == 50 or epoch==75:\n",
    "             # decrease learning rate by 10x & update regularizer\n",
    "             optimizer.update_regularizer(decay_factor=10)\n",
    "\n",
    "         train_pred = []\n",
    "         train_true = []\n",
    "         model.train()    \n",
    "         for data, targets in trainloader:\n",
    "    #          data, targets  = data.cuda(), targets.cuda()\n",
    "             y_pred = model(data)\n",
    "             loss = loss_function(y_pred, targets)\n",
    "             optimizer.zero_grad()\n",
    "             loss.backward()\n",
    "             optimizer.step()\n",
    "\n",
    "             train_pred.append(y_pred.cpu().detach().numpy())\n",
    "             train_true.append(targets.cpu().detach().numpy())\n",
    "\n",
    "         train_true = np.concatenate(train_true)\n",
    "         train_pred = np.concatenate(train_pred)\n",
    "         train_auc = roc_auc_score(train_true, train_pred) \n",
    "\n",
    "         model.eval()\n",
    "         test_pred = []\n",
    "         test_true = [] \n",
    "         for j, data in enumerate(testloader):\n",
    "             test_data, test_targets = data\n",
    "    #          test_data = test_data.cuda()\n",
    "             y_pred = model(test_data)\n",
    "             test_pred.append(y_pred.cpu().detach().numpy())\n",
    "             test_true.append(test_targets.numpy())\n",
    "         test_true = np.concatenate(test_true)\n",
    "         test_pred = np.concatenate(test_pred)\n",
    "         val_auc =  roc_auc_score(test_true, test_pred) \n",
    "         model.train()\n",
    "\n",
    "         # print results\n",
    "         print(\"epoch: {}, train_loss: {:4f}, train_auc:{:4f}, test_auc:{:4f}, lr:{:4f}\".format(epoch, loss.item(), train_auc, val_auc, optimizer.lr ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05a5ab-ecaf-4e74-be45-797ba292bcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
